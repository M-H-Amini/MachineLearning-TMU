{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLe_TMU_Lec7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO0jiHwq1KXhbG16ZjihInI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/MachineLearning-TMU/blob/master/MLe_TMU_Lec7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxv8P7cejYxD"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "# Machine Learning *elementary* Course\n",
        "## Tarbiat Modares University\n",
        "### Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "# Lecture 7\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=144SDpgv7EEy6Og1ZFNIv_nBaugKGiSCE\" width=\"400\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxo_up02YTAr"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW5FtD9qjemD"
      },
      "source": [
        "Today we're gonna see 2 funny applications of **PCA**. The theoretical stuff has been discussed in the video lectures. Let's see what can PCA do in action.\n",
        "\n",
        "\n",
        "\n",
        "*   First, we're going to see some **word embeddings**. In *NLP*, for reasons such as efficient space usage and finding concepts of words, each word is represented as an N-d vector, e.g. 100-d vector. Since, as humans, we can't imagine higher dimension spaces, we must find a way to see how well our word embeddings are. So using PCA, we project each embedding to a 2-d space and plot it.\n",
        "*   Second, we're going to do a **face recognition** task using PCA. We'll be learning eigenfaces from data and represent each face with a small vector. Then we can do a simple supervised learning classification algorithm to find out whose face are we facing :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tqn3ZPzk3rg"
      },
      "source": [
        "#  Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNohVey9vVo1"
      },
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j21SPqo8XXvD"
      },
      "source": [
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOx9CPGbXt8U"
      },
      "source": [
        "with open('glove.6B.100d.txt') as f:\n",
        "  lines = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtCfROAZX1hd"
      },
      "source": [
        "my_dict = dict()\n",
        "for line in lines:\n",
        "  splitted_line = line.split()\n",
        "  word = splitted_line[0]\n",
        "  vec = np.array([float(i) for i in splitted_line[1:]])\n",
        "  my_dict[word] = vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zOrjcgsYcLu"
      },
      "source": [
        "words = []\n",
        "vecs = []\n",
        "for word, vec in my_dict.items():\n",
        "  words.append(word)\n",
        "  vecs.append(vec)\n",
        "vecs = np.array(vecs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-5YccHmY7nW"
      },
      "source": [
        "print(len(words), vecs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBuWQ1nLYQyi"
      },
      "source": [
        "pca = PCA(2).fit(vecs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqXHlvwgZMXE"
      },
      "source": [
        "X = pca.transform(vecs)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAowbImXUfgN"
      },
      "source": [
        "chosen_words = ['coffee', 'tea', 'water',\n",
        "                         'spaghetti', 'borscht', 'hamburger', 'pizza', 'falafel', 'sushi', 'meatballs',\n",
        "                         'dog', 'horse', 'cat', 'monkey', 'parrot', 'koala', 'lizard',\n",
        "                         'frog', 'toad', 'monkey', 'ape', 'kangaroo', 'wombat', 'wolf',\n",
        "                         'france', 'germany', 'hungary', 'luxembourg', 'australia', 'fiji', 'china',\n",
        "                         'homework', 'assignment', 'problem', 'exam', 'test', 'class',\n",
        "                         'school', 'college', 'university', 'institute']\n",
        "\n",
        "chosen_indxs = [words.index(word) for word in chosen_words]\n",
        "X_chosen = X[chosen_indxs, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkzwE8TRZukZ"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.plot(X_chosen[:, 0], X_chosen[:, 1], 'bo')\n",
        "for i in range(len(chosen_words)):\n",
        "  plt.text(X_chosen[i, 0] + 0.05, X_chosen[i, 1] + 0.05, chosen_words[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1guFU3TlMQS"
      },
      "source": [
        "# Face Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtaK2y3gVcR7"
      },
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz\n",
        "!tar -xvzf lfw-funneled.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulWMi7nFbBT0"
      },
      "source": [
        "main_folder = 'lfw_funneled'\n",
        "sub_folders = [f for f in os.listdir(main_folder) if os.path.isdir(os.path.join(main_folder, f))]\n",
        "files_dict = {folder:[os.path.join(main_folder, folder, f) for f in os.listdir(os.path.join(main_folder, folder))] for folder in sub_folders}\n",
        "print(files_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16QwiI40dce7"
      },
      "source": [
        "def processImage(path):\n",
        "  return np.array(Image.open(path).convert('L').resize((40, 40))).reshape((-1, 1))\n",
        "\n",
        "X = []\n",
        "for person in files_dict:\n",
        "  for path in files_dict[person]:\n",
        "    X.append(processImage(path))\n",
        "\n",
        "X = np.array(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TIp0Y3be_pY"
      },
      "source": [
        "X = X[:, :, 0]\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgQWskvIfF9g"
      },
      "source": [
        "pca = PCA(16)\n",
        "X_new = pca.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHJ-uhhJfTy3"
      },
      "source": [
        "efaces = pca.components_\n",
        "print(efaces.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EUr0TJMfgTb"
      },
      "source": [
        "def showEfaces(efaces, r=4, c=4):\n",
        "  plt.figure(figsize=(12,12))\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      plt.subplot(r, c, i * c + j + 1)\n",
        "      plt.imshow(efaces[i * c + j].reshape((40, 40)), cmap='gray')\n",
        "      plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "showEfaces(efaces)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}