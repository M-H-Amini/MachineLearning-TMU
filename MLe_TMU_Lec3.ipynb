{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLe_TMU_Lec3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPVQjr7HOQtAvC9bS0jTpHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/MachineLearning-TMU/blob/master/MLe_TMU_Lec3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYJpsjH8nluG",
        "colab_type": "text"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "# Machine Learning *elementary* Course\n",
        "## Tarbiat Modares University\n",
        "### Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "# Lecture 3\n",
        "\n",
        "<img src=\"https://github.com/M-H-Amini/MachineLearning-AUT/blob/master/stuff/MLAUT.jpg?raw=true\" width=\"400\">\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51Q76GlqYSY",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "In this lecture, we will do sentiment analysis on some tweets using **Logistic Regression**.\n",
        "\n",
        "After preprocessing each tweet, we'll count frequency of its words in both positive and negative tweets. So for each tweet, there are 2 features: Positive and Negative frequencies. we'll use these feature vectors to classify tweets!\n",
        "\n",
        "we would implement logistic regression using **keras**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6g3dUISdojD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk                                  \n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "import matplotlib.pyplot as plt              \n",
        "import numpy as np       \n",
        "import keras\n",
        "from utils import process_tweet, build_freqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEMoAHOLok46",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Preparation\n",
        "Let's download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWt5MD49eEMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm9QGYvQP0wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1CIOCUkoo0z",
        "colab_type": "text"
      },
      "source": [
        "Now we would create some lists containing our tweets as strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQLUTVQheP1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select the lists of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# concatenate the lists, 1st part is the positive tweets followed by the negative\n",
        "tweets = all_positive_tweets + all_negative_tweets\n",
        "\n",
        "# let's see how many tweets we have\n",
        "print(\"Number of tweets: \", len(tweets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3U15czxNUUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(all_positive_tweets[10])\n",
        "print(all_negative_tweets[1543])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RlF0eB4eW6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.append(np.ones((len(all_positive_tweets))), np.zeros((len(all_negative_tweets))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIbBX1Ozo3FO",
        "colab_type": "text"
      },
      "source": [
        "Let's count frequency of each word in both positive and negative tweets. We'd use ```build_freqs``` function for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKkqi24Wea3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freqs = build_freqs(tweets, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFx6hXxsNrL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(freqs[('great', 1)], freqs[('great', 0)])\n",
        "freqs.get(('excellent', 1), 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3A3RDGkpMPP",
        "colab_type": "text"
      },
      "source": [
        "Time for preprocessing and extracting features! ```extractFeatures``` would get a tweet and returns the 2-element feature vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rljh26Dved11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractFeatures(tweet):\n",
        "  tweet = process_tweet(tweet)\n",
        "  pos, neg = 0, 0\n",
        "  for word in tweet:\n",
        "    pos += freqs.get((word, 1.), 0)\n",
        "    neg += freqs.get((word, 0.), 0)\n",
        "  feature_vec = np.array([pos, neg])\n",
        "  return feature_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ac1yFZwpefR",
        "colab_type": "text"
      },
      "source": [
        "Splitting data into train and test now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WttYTI-xfyTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tweets = all_positive_tweets[:4000] + all_negative_tweets[:4000]\n",
        "train_labels = [1. for i in range(4000)] + [0. for i in range(4000)]\n",
        "test_tweets = all_positive_tweets[4000:] + all_negative_tweets[4000:]\n",
        "test_labels = [1. for i in range(1000)] + [0. for i in range(1000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IMdKXRIpiMr",
        "colab_type": "text"
      },
      "source": [
        "We'd have some numpy arrays to keep training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npK6ab7ogcVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.zeros((len(train_tweets), 2))\n",
        "y_train = np.array(train_labels)\n",
        "X_test = np.zeros((len(test_tweets), 2))\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY5CSbDMg2yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(X_train.shape[0]):\n",
        "  X_train[i] = extractFeatures(train_tweets[i])\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "  X_test[i] = extractFeatures(test_tweets[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv14YFZ4poUW",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression\n",
        "Let's do the logistic regression now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tvdWnXhSUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([keras.layers.Dense(1, activation='sigmoid', input_shape=(2,))])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsQ4uXqqht57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuFWxeWViXbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAKedk7jptDQ",
        "colab_type": "text"
      },
      "source": [
        "Testing and seeing our brilliant result would be so fun."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jV1PLMimCL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(all_negative_tweets[-1])\n",
        "print(X_test[-1])\n",
        "print(model.predict(X_test[-1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_c98YvSp2AO",
        "colab_type": "text"
      },
      "source": [
        "And finally, we would create a ```classify``` function which gets a string and classifies it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E18qchXp-KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(tweet):\n",
        "  tweet = extractFeatures(tweet)\n",
        "  return model.predict(tweet[np.newaxis, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXHDGgzJqPDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg = 'I hated it. It was such an awful movie!'\n",
        "pos = 'It was an honor to view this great one!'\n",
        "print(classify(neg), classify(pos))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}